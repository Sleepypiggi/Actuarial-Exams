{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Actuarial Exam Notes Test","title":"**Actuarial Exam Notes**"},{"location":"#actuarial-exam-notes","text":"Test","title":"Actuarial Exam Notes"},{"location":"Placeholder/","text":"Work in progress!","title":"ASA-PA"},{"location":"Placeholder/#work-in-progress","text":"","title":"Work in progress!"},{"location":"2.%20Actuarial%20Mathematics/Overview/","text":"Overview of Actuarial Mathematics These set of exams cover the main concepts needed to evaluate insurance related risks. They are split into two main exams: Fundamentals of Actuarial Mathematics (FAM) Advanced Long Term or Short Term Actuarial Mathematics (ALTAM or ASTAM) This set of notes splits the FAM component into two seperate components for clarity, as the components are not related to one another: FAM-S (Short Term) FAM-L (Long Term) However, the actual FAM exam tests both components together in an MCQ format. It is regarded as one of the tougher examinations due to its wide breadth (due to the unrelated components).","title":"**Overview of Actuarial Mathematics**"},{"location":"2.%20Actuarial%20Mathematics/Overview/#overview-of-actuarial-mathematics","text":"These set of exams cover the main concepts needed to evaluate insurance related risks. They are split into two main exams: Fundamentals of Actuarial Mathematics (FAM) Advanced Long Term or Short Term Actuarial Mathematics (ALTAM or ASTAM) This set of notes splits the FAM component into two seperate components for clarity, as the components are not related to one another: FAM-S (Short Term) FAM-L (Long Term) However, the actual FAM exam tests both components together in an MCQ format. It is regarded as one of the tougher examinations due to its wide breadth (due to the unrelated components).","title":"Overview of Actuarial Mathematics"},{"location":"3.%20Predictive%20Analytics/Exam%20Overview/","text":"Overview of Predictive Analytics Due to the growing relevance of Predictive Analytics , the SOA has added a significant amount of material on the topic into the credentialling process: Exam Statistics for Risk Modelling (SRM) Exam Predictive Analytics (PA) Exam Advanced Topics for Predictive Analytics (ATPA) Exam ATPA was added midway through 2022 to replace Exam IFM. Credit for IFM also counts towards credit for ATPA, thus this set of notes will NOT be covering ATPA. All of them share the same theme of working with models: Constructing predictive models Intepreting their outputs Evaluating their performance Exam SRM covers the theory about the various types of models, tested in the typical MCQ format . Unlike the other exams where most of the questions are quantitative, most of SRM's questions are qualitative . Exam PA tests the same concepts in an applied manner , providing real data and a business problem to navigate through in a written format . Exam ATPA builds on both of these exams, covering more advanced concepts in a business context.","title":"Overview"},{"location":"3.%20Predictive%20Analytics/Exam%20Overview/#overview-of-predictive-analytics","text":"Due to the growing relevance of Predictive Analytics , the SOA has added a significant amount of material on the topic into the credentialling process: Exam Statistics for Risk Modelling (SRM) Exam Predictive Analytics (PA) Exam Advanced Topics for Predictive Analytics (ATPA) Exam ATPA was added midway through 2022 to replace Exam IFM. Credit for IFM also counts towards credit for ATPA, thus this set of notes will NOT be covering ATPA. All of them share the same theme of working with models: Constructing predictive models Intepreting their outputs Evaluating their performance Exam SRM covers the theory about the various types of models, tested in the typical MCQ format . Unlike the other exams where most of the questions are quantitative, most of SRM's questions are qualitative . Exam PA tests the same concepts in an applied manner , providing real data and a business problem to navigate through in a written format . Exam ATPA builds on both of these exams, covering more advanced concepts in a business context.","title":"Overview of Predictive Analytics"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/1.%20Introduction/","text":"Introduction Statistical Models Predictive Analytics is the usage of statistical models to analyze historical or current data to make predictions about the future or unknown events. Every statistical model has two components: Independent Variable(s) Dependent Variables Variable used to make predictions Variable being predicted Free to change the value Depends on the value of indepenent variable Denoted as \\(x\\) Denoted as \\(y\\) They are also commonly referred to as the Predictor and Response variable respectively. Different statistical models assume different relationships between the Independent and Dependent variable - Linear, Non-Linear, Piecewise Constant etc. The goal is to use the model that best captures the true relationship between the variables. Every regression is a mathematical function that contains one or more required Parameters that define the relationship between the Independent and Dependent variables. It is the parameters of the model that distinguishes one model (of the same type) from another. These parameters are Estimated through the analysis of the historical/current data. This process is known as Training the model. The Population refers to the theoretical set of all possible values of the variables. Samples refer to a subset of the population that has been recorded for analysis. Since it is impossible to observe the entire population at once, the recorded to sample to draw conclusions about the population. If the entire population data is used to train the model, then the resulting model is the Population Model , which represents the theoretical relationship between the variables. If a sample is used to train the model, then the resulting model is a Sample Model , which aims to be representative of the population one. The two are distinguished functionally through the Hat notation (^). Population parameters are written without the hat ( \\(x\\) ) while Sample parameters are written with the hat ( \\(\\hat{x}\\) ). Since the sample model is the main model of interest, the hat is often dropped for convenience. Prediction Since the independent variables can be freely changed, they are Deterministic ; NOT random. Naturally, the dependent variable is a Random Variable that follows some unknown probability distribution . To be precise, for every set of independent variables, the dependent variable has a Conditional Probability Distribution dependent on the those independent variables. For instance, the the dependent variable could take any possible value (non-conditional distribution), but given these set of independent variables, the possible values can be narrowed down to a certain range (conditional distribution). \\[ Y|X \\tilde{} \\] The corresponding prediction of the model based on those independent variable is the Expected Value of this conditional distribution, \\(E(Y|X)\\) . The actual value of the prediction is often going to be different from the predicted value. Similarly, we can distinguish the two using the Hat notation as well - the actual value does not contain the hat ( \\(y\\) ) while the predicted one does ( \\(\\hat{y}\\) ). The difference between the actual and predicted value is known as the Error of the model ( \\(\\varepsilon\\) ). It is calculated from the perspective of the actual observation - a positive error implies that the prediction was too low while a negative error implies it was too high. Naturally, since \\(y\\) is a random variable, \\(\\varepsilon\\) is a random variable as well following the same distribution. \\[ \\varepsilon = y - \\hat{y} \\]","title":"Introduction"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/1.%20Introduction/#introduction","text":"","title":"Introduction"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/1.%20Introduction/#statistical-models","text":"Predictive Analytics is the usage of statistical models to analyze historical or current data to make predictions about the future or unknown events. Every statistical model has two components: Independent Variable(s) Dependent Variables Variable used to make predictions Variable being predicted Free to change the value Depends on the value of indepenent variable Denoted as \\(x\\) Denoted as \\(y\\) They are also commonly referred to as the Predictor and Response variable respectively. Different statistical models assume different relationships between the Independent and Dependent variable - Linear, Non-Linear, Piecewise Constant etc. The goal is to use the model that best captures the true relationship between the variables. Every regression is a mathematical function that contains one or more required Parameters that define the relationship between the Independent and Dependent variables. It is the parameters of the model that distinguishes one model (of the same type) from another. These parameters are Estimated through the analysis of the historical/current data. This process is known as Training the model. The Population refers to the theoretical set of all possible values of the variables. Samples refer to a subset of the population that has been recorded for analysis. Since it is impossible to observe the entire population at once, the recorded to sample to draw conclusions about the population. If the entire population data is used to train the model, then the resulting model is the Population Model , which represents the theoretical relationship between the variables. If a sample is used to train the model, then the resulting model is a Sample Model , which aims to be representative of the population one. The two are distinguished functionally through the Hat notation (^). Population parameters are written without the hat ( \\(x\\) ) while Sample parameters are written with the hat ( \\(\\hat{x}\\) ). Since the sample model is the main model of interest, the hat is often dropped for convenience.","title":"Statistical Models"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/1.%20Introduction/#prediction","text":"Since the independent variables can be freely changed, they are Deterministic ; NOT random. Naturally, the dependent variable is a Random Variable that follows some unknown probability distribution . To be precise, for every set of independent variables, the dependent variable has a Conditional Probability Distribution dependent on the those independent variables. For instance, the the dependent variable could take any possible value (non-conditional distribution), but given these set of independent variables, the possible values can be narrowed down to a certain range (conditional distribution). \\[ Y|X \\tilde{} \\] The corresponding prediction of the model based on those independent variable is the Expected Value of this conditional distribution, \\(E(Y|X)\\) . The actual value of the prediction is often going to be different from the predicted value. Similarly, we can distinguish the two using the Hat notation as well - the actual value does not contain the hat ( \\(y\\) ) while the predicted one does ( \\(\\hat{y}\\) ). The difference between the actual and predicted value is known as the Error of the model ( \\(\\varepsilon\\) ). It is calculated from the perspective of the actual observation - a positive error implies that the prediction was too low while a negative error implies it was too high. Naturally, since \\(y\\) is a random variable, \\(\\varepsilon\\) is a random variable as well following the same distribution. \\[ \\varepsilon = y - \\hat{y} \\]","title":"Prediction"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/2.%20Simple%20Linear%20Regression/","text":"Simple Linear Regression Simple Linear Regression (SLR) assumes a Linear Relationship between a Numeric independent and dependent variable . It is the simplest of all forms of statistical models (hence the name), but it is well suited to demonstrate the fundamental concepts of statistical modelling. \\[ y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x \\] Note that Y and X are vectors which represent the collection of all values of the independent variable and their corresponding dependent variable. \\(\\beta_0\\) and \\(\\beta_1\\) are known as the Parameters of the model as they define the relationship between the variables. \\(\\varepsilon\\) is the Error term which is a catch-all for all other factors that the model does not capture.","title":"Simple Linear Regression"},{"location":"3.%20Predictive%20Analytics/ASA-SRM/2.%20Simple%20Linear%20Regression/#simple-linear-regression","text":"Simple Linear Regression (SLR) assumes a Linear Relationship between a Numeric independent and dependent variable . It is the simplest of all forms of statistical models (hence the name), but it is well suited to demonstrate the fundamental concepts of statistical modelling. \\[ y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x \\] Note that Y and X are vectors which represent the collection of all values of the independent variable and their corresponding dependent variable. \\(\\beta_0\\) and \\(\\beta_1\\) are known as the Parameters of the model as they define the relationship between the variables. \\(\\varepsilon\\) is the Error term which is a catch-all for all other factors that the model does not capture.","title":"Simple Linear Regression"}]}