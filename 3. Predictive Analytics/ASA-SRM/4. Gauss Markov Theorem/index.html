
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/3.%20Predictive%20Analytics/ASA-SRM/4.%20Gauss%20Markov%20Theorem/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>Gauss Markov Theorem - Actuarial Exam Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.975780f9.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.2505c338.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="None" data-md-color-accent="None">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#gauss-markov-theorem" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Actuarial Exam Notes" class="md-header__button md-logo" aria-label="Actuarial Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Actuarial Exam Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Gauss Markov Theorem
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Actuarial Exam Notes" class="md-nav__button md-logo" aria-label="Actuarial Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Actuarial Exam Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Foundational
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Foundational" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Foundational
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../0.%20Foundational/1.%20Review%20of%20Linear%20Algebra/" class="md-nav__link">
        Review of Linear Algebra
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../0.%20Foundational/2.%20Review%20of%20Calculus/" class="md-nav__link">
        Review of Calculus
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../0.%20Foundational/3.%20Review%20of%20Statistical%20Theory/" class="md-nav__link">
        Review of Statistical Theory
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Introductory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introductory" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Introductory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-P
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-FM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-IFM
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Actuarial Mathematics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Actuarial Mathematics" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Actuarial Mathematics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-FAMS
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_3">
          ASA-FAML
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA-FAML" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          ASA-FAML
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2.%20Actuarial%20Mathematics/ASA-FAML/1.%20Survival%20Models/" class="md-nav__link">
        Survival Models
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-ALTAM
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Predictive Analytics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Analytics" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Predictive Analytics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Exam%20Overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          ASA-SRM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA-SRM" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          ASA-SRM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20Regression%20Overview/" class="md-nav__link">
        Regression Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20Simple%20Linear%20Regression/" class="md-nav__link">
        Simple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20Multiple%20Linear%20Regression/" class="md-nav__link">
        Multiple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Gauss Markov Theorem
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Gauss Markov Theorem
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ols-assumptions" class="md-nav__link">
    OLS Assumptions
  </a>
  
    <nav class="md-nav" aria-label="OLS Assumptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-linearity" class="md-nav__link">
    #1: Linearity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-exogenity" class="md-nav__link">
    #2: Exogenity
  </a>
  
    <nav class="md-nav" aria-label="#2: Exogenity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#residual-analysis" class="md-nav__link">
    Residual Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-no-perfect-collinearity" class="md-nav__link">
    #3: No Perfect Collinearity
  </a>
  
    <nav class="md-nav" aria-label="#3: No Perfect Collinearity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imperfect-collinearity" class="md-nav__link">
    Imperfect Collinearity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detecting-collinearity" class="md-nav__link">
    Detecting Collinearity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-no-extreme-outliers" class="md-nav__link">
    #4: No Extreme Outliers
  </a>
  
    <nav class="md-nav" aria-label="#4: No Extreme Outliers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#identifying-outliers" class="md-nav__link">
    Identifying Outliers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cooks-distance" class="md-nav__link">
    Cooks Distance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identifying-leverage-points" class="md-nav__link">
    Identifying Leverage Points
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gauss-markov-assumptions" class="md-nav__link">
    Gauss Markov Assumptions
  </a>
  
    <nav class="md-nav" aria-label="Gauss Markov Assumptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-conditional-homoscedasticity" class="md-nav__link">
    #1: Conditional Homoscedasticity
  </a>
  
    <nav class="md-nav" aria-label="#1: Conditional Homoscedasticity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#identifying-heteroscedasticity" class="md-nav__link">
    Identifying Heteroscedasticity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dealing-with-heteroscedasticity" class="md-nav__link">
    Dealing with Heteroscedasticity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-no-serial-correlation" class="md-nav__link">
    #2: No Serial Correlation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#error-distribution" class="md-nav__link">
    Error Distribution
  </a>
  
    <nav class="md-nav" aria-label="Error Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q-q-plots" class="md-nav__link">
    Q-Q Plots
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20Statistical%20Learning/" class="md-nav__link">
        Statistical Learning
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA-PA
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ols-assumptions" class="md-nav__link">
    OLS Assumptions
  </a>
  
    <nav class="md-nav" aria-label="OLS Assumptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-linearity" class="md-nav__link">
    #1: Linearity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-exogenity" class="md-nav__link">
    #2: Exogenity
  </a>
  
    <nav class="md-nav" aria-label="#2: Exogenity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#residual-analysis" class="md-nav__link">
    Residual Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-no-perfect-collinearity" class="md-nav__link">
    #3: No Perfect Collinearity
  </a>
  
    <nav class="md-nav" aria-label="#3: No Perfect Collinearity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#imperfect-collinearity" class="md-nav__link">
    Imperfect Collinearity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detecting-collinearity" class="md-nav__link">
    Detecting Collinearity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-no-extreme-outliers" class="md-nav__link">
    #4: No Extreme Outliers
  </a>
  
    <nav class="md-nav" aria-label="#4: No Extreme Outliers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#identifying-outliers" class="md-nav__link">
    Identifying Outliers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cooks-distance" class="md-nav__link">
    Cooks Distance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#identifying-leverage-points" class="md-nav__link">
    Identifying Leverage Points
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gauss-markov-assumptions" class="md-nav__link">
    Gauss Markov Assumptions
  </a>
  
    <nav class="md-nav" aria-label="Gauss Markov Assumptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-conditional-homoscedasticity" class="md-nav__link">
    #1: Conditional Homoscedasticity
  </a>
  
    <nav class="md-nav" aria-label="#1: Conditional Homoscedasticity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#identifying-heteroscedasticity" class="md-nav__link">
    Identifying Heteroscedasticity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dealing-with-heteroscedasticity" class="md-nav__link">
    Dealing with Heteroscedasticity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-no-serial-correlation" class="md-nav__link">
    #2: No Serial Correlation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#error-distribution" class="md-nav__link">
    Error Distribution
  </a>
  
    <nav class="md-nav" aria-label="Error Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q-q-plots" class="md-nav__link">
    Q-Q Plots
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="gauss-markov-theorem">Gauss Markov Theorem</h1>
<p>Using OLS, the estimated regression parameters will always be <strong>unbiased</strong> under certain assumptions. The <strong>Gauss Markov Theorem</strong> extends this, which states that under certain assumptions, the OLS estimators will have the <strong>lowest variance</strong> among all possible linear unbiased estimators.</p>
<p>In a statistics context, they are said to be the <strong>most efficient</strong> among all other linear unbiased estimators. In a regression context, the OLS estimators are said to be the <strong>Best Linear Unbiased Estimators</strong> (BLUE).</p>
<p>This section will go over the various <strong>assumptions</strong> for both OLS and Gauss Markov Theorem. It will also cover the <strong>diagnostics</strong> to determine if the assumptions have been violated.</p>
<p>The assumptions needed for OLS and the Gauss Markov theorem are often <strong>mixed up with each other</strong> as the assumptions needed for OLS are also needed for the theorem. This set of notes makes a clear distinction between the two.</p>
<!-- Obtained from Stack Exchange User DVL -->
<p><img alt="Regression Assumptions" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Regression%20Assumptions.png" /></p>
<h2 id="ols-assumptions"><strong>OLS Assumptions</strong></h2>
<h3 id="1-linearity"><strong>#1: Linearity</strong></h3>
<p>Linear regression is a model where the <strong>relationship</strong> between the DV and IVs are linear. Thus, the <strong>regression parameters must be linear</strong>, but NOT the DV or IV.</p>
<p>This means that the model is still considered a "Linear Regression" even after a transformation of the DV and/or IV.</p>
<div class="arithmatex">\[
\begin{aligned}
y_i &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2 \\
y_i &amp;= \beta_0 + \beta_1 x^2 + \beta_2 x^3 \\
\ln y_i &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2
\end{aligned}
\]</div>
<h3 id="2-exogenity"><strong>#2: Exogenity</strong></h3>
<p>Exogenity refers to how a variable comes from <strong>outside</strong> the model and is thus <strong>independent of any other variables within the model</strong>.</p>
<p>In a regression context, this comes in the form of the errors having a <strong>conditional mean of 0</strong>, ensuring that the errors are random and thus not related to the IVs.</p>
<div class="arithmatex">\[
E(\varepsilon_i | x_{ij}) = 0 \\
\]</div>
<blockquote>
<p>"Endo" and "Exo" in Greek means "In" and "Out" respectively, which is how the meaning of the words were derived.</p>
</blockquote>
<p>There are two key implications of Exogenity:</p>
<ol>
<li>By the Law of Total Expectations, the <em>unconditional</em> expectation of the error is also 0.</li>
<li>By the Linearity of Conditional Expectations, the expectation of the product of the Error and IVs is 0.</li>
</ol>
<div class="arithmatex">\[
\begin{aligned}
E(\varepsilon_i) = 0 \\
E(\varepsilon_i x_{ij}) = 0
\end{aligned}
\]</div>
<p>Following these two implications, it can be shown that the Covariance between the Error and IVs are also 0, which is another <em>consequence</em> of independence (NOT the other way around).</p>
<div class="arithmatex">\[
\begin{aligned}
Cov (\varepsilon_i, x_{ij})
&amp;= E(\varepsilon_i x_{ij}) - E(\varepsilon_i) * E(x_{ij}) \\
&amp;= 0 - 0 * E(x_{ij}) \\
&amp;= 0
\end{aligned}
\]</div>
<p>Without exogenity, the regression parameters would reflect the <strong>effect of both the IV and the unmodelled variable</strong> within the error term. This causes the OLS <strong>estimate to be biased</strong>, known as the <strong>Omitted Variable Bias</strong>. Since the unmodelled variable confounds the results of the regression, it is known as a <strong>Confounding Variable</strong>.</p>
<!-- Obtained from Statology -->
<p><img alt="Confounding Variables" class="center" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Confounding%20Variable.png" /></p>
<h4 id="residual-analysis"><strong>Residual Analysis</strong></h4>
<p>Since the errors are unobservable, the residuals are used to estimate the errors.</p>
<p>If the fitted model is adequate - all relavent IVs are included in the right form, then the residuals should closely <strong>resemble the errors</strong> and therefore be <strong>structureless</strong> (random). However, if there are <strong>patterns in the residuals</strong>, it indicates that there is additional information that can be used to improve the model and thus should be included.</p>
<p>Due to the OLS, the correlation between residuals and existing IVs will <strong>always be 0</strong> indicating <strong>no linear relationship</strong>. To check for unmodelled <strong>non-linear relationships</strong>, a <strong>Residual Plot</strong> of the IVs against the Residuals can be used.</p>
<p>For instance, if the residual plot shows a quadractic pattern (curve), then a quadractic IV should be added into the model. Mathematically, it can be expressed as a function of the existing estimates:</p>
<div class="arithmatex">\[
\begin{aligned}
\hat{y_i} &amp;= \hat{\beta}_0 + \hat{\beta}_1 x + \hat{\varepsilon}_i \\
\hat{\varepsilon_i} &amp;= \hat{\gamma}_0 + \hat{\gamma}_1 x + \hat{\gamma}_2 x^2 \text{ (From residual plot)} \\
\hat{y_i} &amp;= \hat{\beta}_0 + \hat{\beta}_1 x + \hat{\gamma}_0 + \hat{\gamma}_1 x + \hat{\gamma}_2 x^2 \\
\hat{y_i} &amp;= (\hat{\beta}_0 + \hat{\gamma}_0) + (\hat{\beta}_1 + \hat{\gamma}_1)x + \hat{\gamma}_2 x^2 \\
\hat{y_i} &amp;= \hat{\beta}_0' + \hat{\beta}_1'x + \hat{\beta}_2' x^2
\end{aligned}
\]</div>
<!-- Obtained from ACTEX Manual -->
<p><img alt="Residual Plot" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Residual%20Plot.png" /></p>
<!-- Added variable plots? -->

<h3 id="3-no-perfect-collinearity"><strong>#3: No Perfect Collinearity</strong></h3>
<p>Collinearity refers to when an IV can be expressed as a <strong>linear combination of one or more other IVs</strong>. Perfect collinearity is an extreme case where an IV can be <em>perfectly</em> expressed as a combination of another.</p>
<blockquote>
<p>Technically speaking, Collinearity refers to one to one variable relationship, while Multicollinearity refers to one to many variable relationship, hence "Multi".</p>
</blockquote>
<ol>
<li>Variable is a <strong>multiple</strong> of another: <span class="arithmatex">\(x_1 = cx_2\)</span></li>
<li>Variable <strong>differs by a constant</strong> from another: <span class="arithmatex">\(x_1 = x_2 \pm c\)</span></li>
<li>Variable is an <strong>affine transformation</strong> of another:</li>
<li>Sum of several variables is fixed: <strong>Dummy Variable Trap</strong></li>
</ol>
<p>The issue with perfect collinearity is that it affects the linear algebra used to solve for the coefficients (EG. Two equations to solve for three unknowns). There will be <strong>no unique solutions</strong> - many different values for the coefficients could work equally well.</p>
<h4 id="imperfect-collinearity"><strong>Imperfect Collinearity</strong></h4>
<p>Imperfect Collinearity is a less extreme case where an IV is highly (but not perfectly) correlated with one or more other IVs.</p>
<blockquote>
<p>Recall that correlation refers to the extent of a <em>Linear</em> relationship. Non-linear relationships between variables are fine (EG. Polynomial Regression).</p>
</blockquote>
<p>This means that including the IV does not bring much additional predctive power into the model as its effects are already captured through related predictors and thus can be removed from the model.</p>
<p>Unlike in the perfect case, high collinearity does not prevent OLS from finding a solution. However, the intepretation of the variables become complicated:</p>
<ol>
<li>The original intepretation of coefficients "holding other variables constant" is <strong>no longer true</strong> as highly correlated variables tend to move together. Thus, it is <strong>hard to seperate the effects of an individual variable</strong>.</li>
<li>Consequently, OLS has difficulty estimating these coefficients, which could result in <strong>weird meaningless estimates</strong>; EG. Large positive coefficient but large negative for its correlated counterpart.</li>
<li>This also results in <strong>higher standard errors</strong> for the coefficients of correlated variables. This <strong>reduces the magnitude of t-statistic</strong>, which results in <strong>more false negatives</strong>, failing to reject the null when it should. This results in important variables being omitted from the regression.</li>
</ol>
<p>Technically speaking, there is <em>nothing wrong</em> with collinearity if the purpose of the model is solely for prediction. However, if the purpose of the model was to establish causality, then collinearity poses a problem as it interferes with statistical inference.</p>
<h4 id="detecting-collinearity"><strong>Detecting Collinearity</strong></h4>
<p>The simplest way to detect collinearity is through a <strong>Scatterplot or Correlation Matrix</strong>, which shows the correlations between <strong>pairs of variables</strong>. A <strong>correlation of 0.8 and higher</strong> is typically considered high enough where the collinearity becomes problematic.</p>
<!-- Obtained from ACTEX Manual -->
<p><img alt="Correlation Matrix" class="center" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Correlation%20Matrix.png" /></p>
<p>However, the issue is that this method can only detect collinearity between pairs of variable at a time. In order to detect collinearity among three or more variables (<em>multicollinearity</em>), then the <strong>Variance Inflation Factor (VIF)</strong> should be used instead.</p>
<div class="arithmatex">\[
VIF = \frac{1}{1-R^2_j}
\]</div>
<p>The VIF is derived from the variance of the regression coefficient. As mentioned previously, under the presence of collinearity, the standard error and hence <strong>variance of the coefficient increases</strong> ("inflated"). The <em>extent</em> of the increase is known as the VIF.</p>
<div class="arithmatex">\[
\hat{Var}(\hat{\beta_1}) = \frac{MS_{RSS}}{(n-1) s^2} * \frac{1}{1-R^2_j}
\]</div>
<p>The <span class="arithmatex">\(R^2_j\)</span> in the VIF is the coefficient of determination of a model where the <strong>jth IV is regressed against all other IVs</strong>. A high <span class="arithmatex">\(R^2_j\)</span> means that the <strong>IV is well explained by the other IVs</strong> (high correlation), which indicates the presence of collinearity. Generally, a <span class="arithmatex">\(VIF &gt; 10\)</span> is deemed to have <em>severe collinearity</em>.</p>
<h3 id="4-no-extreme-outliers"><strong>#4: No Extreme Outliers</strong></h3>
<p>Outliers are observations with <strong>unusual values of the DV</strong> relative to majority of the observations.</p>
<p>The last OLS assumption is that there are <strong>no extreme outliers</strong> in the dataset used to create the regression model. Generally, as long as the DV and IVs have a <strong>positive and finite Kurtosis</strong>, then the probability of such observations occuring are low.</p>
<p>Outliers are problematic as OLS is <strong>sensitive to outliers</strong>. Extreme outliers have large residuals which <strong>receive more weight</strong> in the optimization process, which causes the resulting model to accomodate it (when it should not), causing the resulting coefficients to be biased.</p>
<!-- Obatained from Research Gate -->
<p><img alt="Outliers" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Outliers.png" /> {.center}</p>
<h4 id="identifying-outliers"><strong>Identifying Outliers</strong></h4>
<p>Outliers
Unusual values of Y relative to the predicted values, large residuals
Hard to gauge how large is large &gt; Standardize the residuals to compare
However, need to know sampling distribution of the residuals
Larger than 2 or 3 is considered outlier</p>
<p>Example from actex: Not unusual in x1 or x2 but unusual when taken collectively</p>
<p>Average leverage
Exceed three times the average to be considered large</p>
<p>Measure of remoteness</p>
<h4 id="cooks-distance"><strong>Cooks Distance</strong></h4>
<p>Influence definition
Fit the main model
Fit the model without the observation want to test
the bigger the difference, the more influential that observation</p>
<p>Cooks distance takes this for all points on the whole model etc
Expected value of D is 1/n, so anything larger than that is large</p>
<p>Need n+1 datasets
dataset with all observations to get mse and y
then n datasets that each exclude one of the observations</p>
<p>Can be expressed algebraically as well
Product of studentized residual and leverage &gt; Need to be large in both X and Y axis to be influential</p>
<p>Unity threshold</p>
<h4 id="identifying-leverage-points"><strong>Identifying Leverage Points</strong></h4>
<p>Leverage is unusual values of X
Visually easy for one variable &gt; far away from the majority in the X axis
Visually hard for multiple &gt; could lie in the range of each variable but far away collectively</p>
<h2 id="gauss-markov-assumptions"><strong>Gauss Markov Assumptions</strong></h2>
<h3 id="1-conditional-homoscedasticity"><strong>#1: Conditional Homoscedasticity</strong></h3>
<p>Homoscedasticity refers to the error terms having <strong>constant variance</strong> while Heteroscedasticity refers to having non-constant variance.</p>
<div class="arithmatex">\[
var(\varepsilon_i | x_i) = \sigma^2
\]</div>
<p>Under homoscedasticity, the sampling distribution of the estimates are easily derived and thus it can be shown that they are the most efficient estimators. The same cannot be proven under heteroscedasticity.</p>
<blockquote>
<p>Note that that the OLS estimates are still unbiased; they are just not the most efficient.</p>
</blockquote>
<h4 id="identifying-heteroscedasticity"><strong>Identifying Heteroscedasticity</strong></h4>
<p>Similar to before, if the model is adequate, then the residuals should resemble the errors and have <strong>constant variance</strong>. Thus, this can be easily determined through a <strong>residual plot</strong> of the Residuals against the fitted values.</p>
<p>If the points are <strong>equally spread out</strong> about the mean (0) and show <strong>no pattern</strong>, then homoscedasticity is present. However, if the points show an increasing or decreasing variance (typically in the <strong>shape of a funnel</strong>), then heteroscedasticity is present.</p>
<!-- Obtained from Corporate Finance Institute -->
<p><img alt="Homoscedastacity" class="center" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/Homoscedasticity.png" /></p>
<p>Alternatively, a hypothesis test can be conducted to determine if heteroscedasticity is present, known as the <strong>Bresuch Pagan Test</strong>.</p>
<div class="arithmatex">\[
\begin{aligned}
H_0: \sigma^2
H_1: \sigma^2 + \boldsymbol{Z\gamma}
\end{aligned}
\]</div>
<p>The test-statistic is computed as follows:</p>
<ol>
<li>Compute the squared standardized residuals from the original model</li>
<li>Regress them onto the variables in Z (LOL need to change this part)</li>
<li>Compute the RegSS of the new regression</li>
</ol>
<div class="arithmatex">\[
T = \frac{RegSS}{2}
\]</div>
<p>The test-statistic follows a <strong>chi-square distribution</strong> with <span class="arithmatex">\(q\)</span> degrees of freedom, where <span class="arithmatex">\(q\)</span> is the <strong>number of variables</strong> in <span class="arithmatex">\(\boldsymbol{Z}\)</span>.</p>
<div class="arithmatex">\[
T \sim \chi^2_q
\]</div>
<h4 id="dealing-with-heteroscedasticity"><strong>Dealing with Heteroscedasticity</strong></h4>
<p>If prior information is known about the structure of the data, then the most intuitive method would be to incorporate that information into the data.</p>
<div class="arithmatex">\[
Var(\varepsilon_i) = \frac{\sigma^2}{w_i}
\]</div>
<p>If no prior information is known, then the Heteroscedasticity can be reduced by using a <strong>Variance Stabilizing Transformation</strong>, such as the <strong>Log</strong> or <strong>Squareroot</strong>. Note that since they require positive data, a <strong>constant can be added</strong> to each term before the transformation to ensure that the values are positive.</p>
<blockquote>
<p>It is out of the scope for this set of notes to show why these help to stabilize variance.</p>
</blockquote>
<p>Alternatively, if there is only mild heteroscedasticity in the data, then OLS can be used but with an <strong>adjustment to the standard errors</strong> of the coefficients, known as <strong>heteroscedastic-robust standard errors</strong>.</p>
<p>Due to complexity of the computations, it will not be covered in this set of notes. However, the general idea is that an <strong>weighted estimate</strong> of the variance covariance matrix is computed and the standard errors are computed from there.</p>
<h3 id="2-no-serial-correlation"><strong>#2: No Serial Correlation</strong></h3>
<p>If errors are correlated with one another, it is known as <strong>Serial Correlation</strong> or <strong>Autocorrelation</strong>.</p>
<p>It implies that there are other unmodelled factors that can be used for prediction, which would imply the current model specification to be wrong.</p>
<p>Thus, for the SLR model to be true, the errors <strong>must be independent of one another</strong>.</p>
<div class="arithmatex">\[
Cov(\varepsilon_i,\varepsilon_j) = 0
\]</div>
<p>Confidence Intervals and PI are narrower than it should be &gt; 95% PI is actually &lt; 95%&gt;
P values lower &gt; Appear statisticlaly significant when they shld not be</p>
<p>Time series tends to have errors that are positively correlated, which is why it has its own dedicated section
No Serial Correlation &gt; Outcome of zero conditional mean, but most likely in time series data</p>
<h2 id="error-distribution"><strong>Error Distribution</strong></h2>
<p>Although not needed for OLS estimation or Guass Markov, the errors of the regression are usually assumed to be <strong>normally distributed</strong>.</p>
<!-- To check on specific normal distributions for Y > Does it have the same variance as E? -->
<div class="arithmatex">\[
\varepsilon \sim N(0, \sigma^2)
\]</div>
<p>If the errors are normally distributed, then it follows that <strong><span class="arithmatex">\(\beta\)</span> is normally distributed</strong> as well since they are linear and additive. This greatly eases the computation needed to determine the <strong>sampling distribution</strong> for statistical inference.</p>
<h3 id="q-q-plots"><strong>Q-Q Plots</strong></h3>
<p>Since the errors are normally distributed, the residuals should be normally distributed as well. This can be verified using a <strong>Quantile-Quantile Plot (QQ Plot)</strong>, which <strong>compares the quantiles</strong> of two distributions.</p>
<p>The first distribution is plotted on the x-axis while the second on the y-axis. If the quantiles are the same, then the points should lie on <span class="arithmatex">\(y = x\)</span>, the 45 degree line.</p>
<!-- Obtained from STHDA -->
<p><img alt="QQ Plot" src="../Assets/4.%20Gauss%20Markov%20Theorem.md/QQ%20Plot.png" /></p>
<!-- Simple random sample refer to Econometrics bible -->





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../3.%20Multiple%20Linear%20Regression/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Multiple Linear Regression" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Multiple Linear Regression
            </div>
          </div>
        </a>
      
      
        
        <a href="../5.%20Statistical%20Learning/" class="md-footer__link md-footer__link--next" aria-label="Next: Statistical Learning" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Statistical Learning
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.5a2dcb6a.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
    
  </body>
</html>