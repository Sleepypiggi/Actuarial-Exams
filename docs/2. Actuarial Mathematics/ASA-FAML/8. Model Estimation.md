# **Model Estimation**

## **Overview**

Previously, mortality rates were obtained through some parametric distribution. However, this requires us to make an assumption about the population, which may not always hold true.

Thus, a better method would be to **study the underlying population directly** to estimate the mortality rates.

## **Complete Data**

Consider a study where a group of individuals of the **same age** are observed till they die. The **number of years** taken for each individual to *die* are recorded as **observations** in the study.

Each study has a total of $n$ individuals starting at age $x$, thus the observations are denoted as $t_1, t_2, ..., t_n$.

### **Individual Data**

If each indvidual has an observation tagged to them (similar to what was described earlier), then **Individual Data** is provided.

**Equal probability** is assigned to each observation, thus the probability of an individual aged $x$ surviving $k$ years is simply the **ratio** of the number of observations larger than $k$ to the total number of observations:

$$
    \hat{S}_x(t) = \frac{\text{# of observations larger than k}}{n}
$$

### **Grouped Data**

If the population of the study is large, then the data is usually **Grouped** into ranges for convenience. The **number of observations** within each range is also provided.

Ranges are concisely expressed using the bracket notation - () denotes that the bound is exlcusive while [] denotes that it is inclusive. For instance, (15, 20] denoted that the time to death is strictly larger than 15 but less than or equal to 20; $15 \lt 5 \le 20$.

<!-- Obtained from Coaching Actuaries -->
![Grouped Data](Assets/8.%20Model%20Estimation.md/Grouped%20Data.png){.center}

If $k$ is the **boundary of any of the ranges**, then the probability of surviving $k$ years is calculated the **same way as the individual data** - it is the ratio of the number of observations to the total number:

$$
    \hat{S}_x(t) = \frac{\text{# of observations larger than k}}{n}
$$

However, if $k$ is within the range, by assuming that values within the range are **uniformly distributed**, then the probability can be **linearly interpolated** from the probabilities at the boundary:

Consider the range $(a,b]$:

$$
    \hat{S}_x(t) = \frac{k-a}{b-a} \cdot \hat{S}_x(a) + \frac{b-k}{b-a} \cdot \hat{S}_x(b)
$$

<!-- Obtained from Coaching Actuaries -->
![Grouped Interpolation](Assets/8.%20Model%20Estimation.md/Grouped%20Interpolation.png){.center}

The interpolation follows the same intuition as the fractional age assumption, where the uniform assumption results in a linear graph of probabilities:

<!-- Obtained from Coaching Actuaries -->
![Graphical Interpolation](Assets/8.%20Model%20Estimation.md/Graphical%20Interpolation.png){.center}

## **Incomplete Data**

In practice, due to various constraints, it is impossible to observe an *entire* group of individuals till they die. Thus, for some observations, the recorded time to death is **not the exact time to death**, known as **Incomplete Data**.

### **Censoring**

Censoring refers to when the value of the observation is only **partially known**.

For instance, if the study stops prematurely, the time to deaths for the individuals alive will be recorded at the time the study ends. However, in reality, they die at some future time, resulting in a **larger time to death than what was recorded**.

* **Right Censored** - Actual value is larger than the recorded value
* **Left Censored** - Actual value is smaller than the recorded value
* Naturally, since time to death is an increasing function, the only Right Censored data is relevant in an actuarial context

Generally speaking, there are two types for censored data:

* **Type 1 Censoring** - Study is stopped at a pre-determined time
* **Type 2 Censoring** - Study is stopped a certain number of deaths
* The remaining individuals still in the study at the point of stopping are right censored

> Interval censoring is grouped data, random censoring

### **Truncation**

Truncation refers to when the sample **does not contain certain observations** outside of some range.

> This is not to be confused with its mathematical definition of rounding.

For instance, consider a study that wishes to study the mortality for people aged 50. However, only people aged 52 are able to be found. Naturally, then the times to death *from age 50* for these individuals will always be **at least 2**; it will **never be smaller than 2**.

* **Right Truncated** - No observations with values larger than cutoff
* **Left Truncated** - No observations with values smaller than cutoff
* Naturally, since time to death is an increasing function, the only **Left Truncated** data is relevant in an actuarial context

Truncation and Censoring are often confused with one another as both result in observations within a given range. Truncation is when observations outside the range are **not recorded at all** while **Censoring still records the observations**, with the caveat that it is a floor/ceiling.

### **Kaplan Meier Estimation**

Consider a study of 5 individuals:

* One individual dies at $t=0.8$ and $t=1.4$
* 5 more individuals join the study at $t=1$; Left Truncated at $t=1$
* 3 individual leave the study at $t=0.5$; Right Censored at $t=0.5$

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Timeline](Assets/8.%20Model%20Estimation.md/Kaplan%20Meier%20Timeline.png){.center}

The information is more often concisely portrayed in a table format:

* $t$ represents the **time** of death
* $d$ represents the number of **deaths**
* $r$ represents the **risk set** RIGHT BEFORE death; simply known as the **sample size**

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Table](Assets/8.%20Model%20Estimation.md/Kaplain%20Meier%20Table.png){.center}

This is problematic as the **sample size changes** throughout the study. However, the **Kaplan Meier** method accounts for this by calculating the survival probability as the **product** of the **survival probabilities** for **all previous intervals between deaths**:

$$
    \hat{S}_x(1.4) = \prod \left(1-\frac{d_j}{r_j} \right)
$$

Given the above example, the resulting Kaplan Meier estimation would be:

$$
\begin{aligned}
    \hat{S}_x(1.4)
    &= P(t > 0.8) * P(t > 1.4 | x > 0.8) \\
    &= (1 - \frac{1}{2}) * (1 - \frac{1}{6})
    &= (\frac{1}{2}) * (\frac{5}{6}) \\
    &= \frac{5}{12}
\end{aligned}
$$

This results in a **constant probability between deaths**. Thus, the focus is on the **times of death**; the entries and exits from the study are only used to change the sample size.

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Cumulative](Assets/8.%20Model%20Estimation.md/Kaplan%20Meier%20Cumulative.png){.center}

<!-- Tail Correction -->

### **Nelson Aelen Estimation**

Recall that the survival probability can be expressed as a function of the Force of Mortality:

$$
    S_x(t) = e^{- \int^t_0 \mu_{x+t}}
$$

The **Nelson Aelen** method estimates the **Cumulative Force of Mortality** (the exponent of the expression), which can be then used to compute the survival probability.

> It is an extremely common mistake to take the result of the Nelson Aelen estimation as the survival probability.

The nelson aelen estimator is computed as the **sum** of the **death probabilities** for **all previous intervals between deaths**:

$$
    \int^t_0 \mu_{x+t} = \sum \frac{d_j}{r_j}
$$

Given the previous example, the resulting Nelson Aelen estimation would be:

$$
\begin{aligned}
    \int^t_0 \mu_{x+1.4}
    &= P(t < 0.8) + P(t < 1.4 | x > 0.8) \\
    &= (\frac{1}{2}) + (\frac{1}{6}) \\
    &= \frac{2}{3} \\
    \\
    \hat{S}_x(1.4)
    &= e^{-\frac{2}{3}} \\
    &= 0.51171
\end{aligned}
$$

DO NOT confuse the two estimation methods:

| Kaplan Meier | Nelson Aelen |
| :-: | :-: |
| Estimates Survival Probability | Estimates Cumulative Force of Mortality |
| Uses Survival probabilities | Uses Death probabilities |


## **Variance**

Estimation depend on sample
Sampling variance

### **Greenwood Approximation**

## **Alive Dead Model**
