# **Model Estimation**

## **Overview**

Previously, mortality rates were obtained through some parametric distribution. However, this requires us to make an assumption about the population, which may not always hold true.

Thus, a better method would be to **study the underlying population directly** to estimate the mortality rates.

## **Complete Data**

Consider a study where a group of individuals of the **same age** are observed till they die. The **number of years** taken for each individual to *die* are recorded as **observations** in the study.

Each study has a total of $n$ individuals starting at age $x$, thus the observations are denoted as $t_1, t_2, ..., t_n$.

### **Individual Data**

If each indvidual has an observation tagged to them (similar to what was described earlier), then **Individual Data** is provided.

**Equal probability** is assigned to each observation, thus the probability of an individual aged $x$ surviving $k$ years is simply the **ratio** of the number of observations larger than $k$ to the total number of observations:

$$
    {}_{t}\hat{p}_x = \frac{\text{# of individuals survive past k}}{n}
$$

### **Grouped Data**

If the population of the study is large, then the data is usually **Grouped** into ranges for convenience. The **number of observations** within each range is also provided.

Ranges are concisely expressed using the bracket notation - () denotes that the bound is exlcusive while [] denotes that it is inclusive. For instance, (15, 20] denoted that the time to death is strictly larger than 15 but less than or equal to 20; $15 \lt 5 \le 20$.

<!-- Obtained from Coaching Actuaries -->
![Grouped Data](Assets/8.%20Model%20Estimation.md/Grouped%20Data.png){.center}

If $k$ is the **boundary of any of the ranges**, then the probability of surviving $k$ years is calculated the **same way as the individual data** - it is the ratio of the number of observations to the total number:

$$
    {}_{t}\hat{p}_x = \frac{\text{# of observations larger than k}}{n}
$$

However, if $k$ is within the range, by assuming that values within the range are **uniformly distributed**, then the probability can be **linearly interpolated** from the probabilities at the boundary:

Consider the range $(a,b]$:

$$
    {}_{t}\hat{p}_x = \frac{k-a}{b-a} \cdot \hat{S}_x(a) + \frac{b-k}{b-a} \cdot \hat{S}_x(b)
$$

<!-- Obtained from Coaching Actuaries -->
![Grouped Interpolation](Assets/8.%20Model%20Estimation.md/Grouped%20Interpolation.png){.center}

The interpolation follows the same intuition as the fractional age assumption, where the uniform assumption results in a linear graph of probabilities:

<!-- Obtained from Coaching Actuaries -->
![Graphical Interpolation](Assets/8.%20Model%20Estimation.md/Graphical%20Interpolation.png){.center}

## **Incomplete Data**

In practice, due to various constraints, it is impossible to observe an *entire* group of individuals till they die. Thus, for some observations, the recorded time to death is **not the exact time to death**, known as **Incomplete Data**.

### **Censoring**

Censoring refers to when the value of the observation is only **partially known**.

For instance, if the study stops prematurely, the time to deaths for the individuals alive will be recorded at the time the study ends. However, in reality, they die at some future time, resulting in a **larger time to death than what was recorded**.

* **Right Censored** - Actual value is larger than the recorded value
* **Left Censored** - Actual value is smaller than the recorded value
* Naturally, since time to death is an increasing function, the only Right Censored data is relevant in an actuarial context

Generally speaking, there are two types for censored data:

* **Type 1 Censoring** - Study is stopped at a pre-determined time
* **Type 2 Censoring** - Study is stopped a certain number of deaths
* The remaining individuals still in the study at the point of stopping are right censored

Censored data are usually denoted by a '+' superscript.

> Interval censoring is grouped data, random censoring

### **Truncation**

Truncation refers to when the sample **does not contain certain observations** outside of some range.

> This is not to be confused with its mathematical definition of rounding.

For instance, consider a study that wishes to study the mortality for people aged 50. However, only people aged 52 are able to be found. Naturally, then the times to death *from age 50* for these individuals will always be **at least 2**; it will **never be smaller than 2**.

* **Right Truncated** - No observations with values larger than cutoff
* **Left Truncated** - No observations with values smaller than cutoff
* Naturally, since time to death is an increasing function, the only **Left Truncated** data is relevant in an actuarial context

Truncation and Censoring are often confused with one another as both result in observations within a given range. Truncation is when observations outside the range are **not recorded at all** while **Censoring still records the observations**, with the caveat that it is a floor/ceiling.

### **Kaplan Meier Estimation**

Consider a study of 5 individuals:

* One individual dies at $t=0.8$ and $t=1.4$
* 5 more individuals join the study at $t=1$; Left Truncated at $t=1$
* 3 individual leave the study at $t=0.5$; Right Censored at $t=0.5$

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Timeline](Assets/8.%20Model%20Estimation.md/Kaplan%20Meier%20Timeline.png){.center}

The information is more often concisely portrayed in a table format:

* $t$ represents the **time** of death
* $d$ represents the number of **deaths**
* $r$ represents the **risk set** RIGHT BEFORE death; simply known as the **sample size**

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Table](Assets/8.%20Model%20Estimation.md/Kaplain%20Meier%20Table.png){.center}

This is problematic as the **sample size changes** throughout the study. However, the **Kaplan Meier** method accounts for this by calculating the survival probability as the **product** of the **survival probabilities** for **all previous intervals between deaths**:

$$
    {}_{t}\hat{p}_x = \prod \left(1-\frac{d_j}{r_j} \right)
$$

Given the above example, the resulting Kaplan Meier estimation would be:

$$
\begin{aligned}
    {}_{1.4}\hat{p}_0
    &= P(t > 0.8) * P(t > 1.4 | x > 0.8) \\
    &= \left (1 - \frac{1}{2} \right) * \left (1 - \frac{1}{6} \right) \\
    &= \left (\frac{1}{2} \right) * \left (\frac{5}{6} \right) \\
    &= \frac{5}{12}
\end{aligned}
$$

This results in a **constant probability between deaths**. Thus, the focus is on the **times of death**; the entries and exits from the study are only used to change the sample size.

<!-- Obtained from Coaching Actuaries -->
![Kaplan Meier Cumulative](Assets/8.%20Model%20Estimation.md/Kaplan%20Meier%20Cumulative.png){.center}

<!-- Tail Correction -->

### **Nelson Aelen Estimation**

Recall that the survival probability can be expressed as a function of the Force of Mortality:

$$
    {}_{t}\hat{p}_x = e^{- \int^t_0 \mu_{x+t}}
$$

The **Nelson Aelen** method estimates the **Cumulative Force of Mortality** (the exponent of the expression), which can be then used to compute the survival probability.

> It is an extremely common mistake to take the result of the Nelson Aelen estimation as the survival probability.

The nelson aelen estimator is computed as the **sum** of the **death probabilities** for **all previous intervals between deaths**:

$$
    \int^t_0 \mu_{x+t} = \sum \frac{d_j}{r_j}
$$

Given the previous example, the resulting Nelson Aelen estimation would be:

$$
\begin{aligned}
    \int^t_0 \mu_{x+1.4}
    &= P(t < 0.8) + P(t < 1.4 | x > 0.8) \\
    &= \left (\frac{1}{2} \right) + \left (\frac{1}{6} \right) \\
    &= \frac{2}{3} \\
    \\
    {}_{1.4}\hat{p}_x
    &= e^{-\frac{2}{3}} \\
    &= 0.51171
\end{aligned}
$$

> Notice that the two values are not too far off from one another.

<center>

| Kaplan Meier | Nelson Aelen |
| :-: | :-: |
| Estimates Survival Probability | Estimates Cumulative Force of Mortality |
| Uses Survival probabilities | Uses Death probabilities |

</center>

### **Maximum Likelihood Estimation**

Unlike the Nelson Aelen method, the MLE **DIRECTLY estimates the force of mortality**, which can be then used to compute survival probabilities.

One key concept is the idea of **Central Exposed to Risk** ($E^c_x$), which is a measure of *how long* the individual has been **alive in the study** at the time.

Consider the following example to estimate the force of mortality at **age 51**:

<!-- Obtained from Coaching Actuaries -->
![CER Example A](Assets/8.%20Model%20Estimation.md/CER%20Example%20A.png){.center}

Firstly, we need to determine if and when the individuals turn 51:

<!-- Obtained from Coaching Actuaries -->
![CER Example B](Assets/8.%20Model%20Estimation.md/CER%20Example%20B.png){.center}

The **date they turn 51** is used as the **starting point** for the $E^c_x$. The ending point is based on the **year that they turn 51** and is one of the following:

* **Date of death** - Died during the year
* **Date of withdrawal** - Left during the year
* **Date they turn 52** - Survived the entire year

From this, $E^c_x$ is calculated **in years**:

<!-- Obtained from Coaching Actuaries -->
![CER Example C](Assets/8.%20Model%20Estimation.md/CER%20Example%20C.png){.center}

Using the CER, the force of mortality can be determined:

$$
    \hat{\mu}_x = \frac{d_x}{E^c_x}
$$

Assuming that this **force is constant**, the resulting survival probability is calculated as:

$$
    {}_{t}\hat{p}_x = e^{-\hat{\mu}_x}
$$

## **Statistical Inference**

Given that all the above methods are estimates of the survival probability, the estimated values will change depending on the underlying sample.

Thus, it is important to consider the variance of the estimator as well across various different samples.

### **Complete Variance**

Each individual is either **dead or or alive** - thus, the number of people who survive past the specified time can be modelled using a **Bernoulli Random variable**.

Recall that the variance of the bernoulli distribution is:

$$
    Var(\text{# of individuals survive past t}) = n \cdot {}_{t}p_x \cdot (1-{}_{t}p_x)
$$

Thus, the variance of the 

$$
\begin{aligned}
    Var({}_{t}\hat{p}_x)
    &= Var \left(\frac{\text{# of individuals survive past k}}{n} \right) \\
    &= \frac{1}{n^2} Var(\text{# of individuals survive past t}) \\
    &= \frac{1}{n^2} n \cdot {}_{t}p_x \cdot (1-{}_{t}p_x) \\
    &= \frac{{}_{t}p_x \cdot (1-{}_{t}p_x)}{n} \\
\end{aligned}
$$

Since the actual survival probability is not known, it is often substituted with the estimate:

$$
    Var({}_{t}\hat{p}_x) = \frac{{}_{t}\hat{p}_x \cdot (1-{}_{t}\hat{p}_x)}{n}
$$

Note that the variance of the estimated death probability is **identical** to that of the survival probability:

$$
\begin{aligned}
    Var({}_{t}\hat{q}_x)
    &= Var(1 - {}_{t}\hat{p}_x) \\
    &= Var({}_{t}\hat{p}_x) \\
\end{aligned}
$$

### **Incomplete Variance**

Due to the complexity of calculating the variance under these methods, the formula for variances are provided in the formula sheets.

**Kaplan Meier Variance**:

$$
    Var({}_{t}\hat{p}_x) = ({}_{t}\hat{p}_x)^2 \sum \frac{d_j}{r_j (r_j - d_j)}
$$

**Nelson Aelen Variance**:

$$
    Var({}_{t}\hat{p}_x) = ({}_{t}\hat{p}_x)^2 \sum \frac{d_j (r_j - d_j)}{r^3_j}
$$

**Maximum Likelihood Variance**:

$$
    Var({}_{t}\hat{p}_x) = ({}_{t}\hat{p}_x)^2 \cdot \frac{d_x}{\left( E^c_x \right)^2}
$$

### **Confidence Intervals**

Linear
Log Transformed