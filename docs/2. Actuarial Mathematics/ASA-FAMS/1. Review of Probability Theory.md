# **Review of Probability Theory**

## **Basic Probability**

Probability is the study of **Experiments** whose results cannot be predicted with certainty. The result of such an experiment is known as its **Outcome**.

The **Sample Space** $\left(\Omega \right)$ is the *set* of ALL possible outcomes from an experiment. The **Event Space** $(E)$ is a *subset* of the sample space, representing only the outcomes that we are interested in studying. Conversely, its **Complement** $(E^c)$ is the set of all OTHER outcomes not inside $E$.

The probability of the event occuring is the ratio of the **number of elements** in the event to the sample space. It is a measure of the *chance* that the outcome of the experiment is inside the event space.

$$
    P(E) = \frac{n(E)}{n\left(\Omega \right)}
$$

Consider the probability of rolling an odd number on a standard dice:

* **Experiment** - Rolling a dice
* **Outcome** - The number showed on the dice
* **Sample Space** - ${1, 2, 3, 4, 5, 6}$
* **Event Space** - ${1, 3, 5}$
* **Complement** - ${2, 4, 6}$
* **Probability of Event** - $\frac{3}{6}$
* **Probability of Complement** - $\frac{3}{6}$

Within the same experiment, there may be multiple events of interest. For any two events A and B, its **Union** $(A \cup B)$ is the set with outcomes that are **either in A or B** while their **Intersection** $(A \cap B)$ is the set with outcomes that are **in BOTH A and B**.

If both A and B have no outcomes in common $(A \cap B = \emptyset)$, then they are said to be **Mutually Exclusive**. Naturally, an event and its complement are always mutually exclusive.

!!! Warning

    The following *seems intuitive*, but is actually a common mistake:

    $$
        (A \cap B)^c \ne A^c \cap B^c
    $$

    This is properly explained through **De-morgans Law**:

    <!-- Obtained from OnlineMathLearning -->
    ![DeMorgan](Assets/1.%20Review%20of%20Probability%20Theory.md/DeMorgan.png)

    It can be easily remembered by applying the complement to all components of the expression, **including the intersection/union symbol**:

    $$
    \begin{aligned}
        \cap^c &= \cup \\
        \cup^c &= \cap
    \end{aligned}
    $$

### **Probability Axioms**

**Axiom 1** states that all probabilities must be **non-negative**:

$$
    P(E) \ge 0
$$

**Axiom 2** states that probability of the Sample Space is exactly equal to 1:

$$
    P(\Omega) = 1
$$

**Axiom 3** states the probability of a union of **mutually exclusive** events is equal to the sum of their probabilities, known as **Countable Additivity**.

$$
\begin{aligned}
    A \cap B &= \emptyset \\
    P(A \cup B) &= P(A) + P(B)
\end{aligned}
$$

Based on these axioms, several other important properties can also be deduced:

* **Monoticity**: $A \subset B \rightarrow P(A) \le P(B)$
* **Empty Set**: $P(\emptyset) = 0$
* **Complement Rule**: $P(E^c) = 1 - P(E)$
* **Numeric Bound**: $0 \le P(E) \le 1$
* **Sum Rule**:  $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

### **Conditional Probability**

Conditional Probabilities are denoted by $P(A|B)$, which is the probability of event A occuring **given that event B has already occurred**.

The intuition is best understood by considering the following - Given that event B has already occured, what is the probability that event A also occurs?

The event space is $A \cap B$, as we are interested in the probability that both A and B occur. However, since event B has already occured, the sample space is no longer all possible outcomes but rather the event space for B!

$$
\begin{aligned}
    P(A|B)
    &= \frac{n(A \cap B)}{n(B)} \\
    &= \frac{\frac{n(A \cap B)}{n(\Omega)}}{\frac{n(B)}{n(\Omega)}} \\
    &= \frac{P(A \cap B)}{P(B)}
\end{aligned}
$$

Following this expression, the **probability of an intersection** of two events is given by:

$$
    P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)
$$

<!-- Obtained from Probability Course -->
![Conditional Probability](Assets/1.%20Review%20of%20Probability%20Theory.md/Conditional%20Probability.png)

Most experiments involving conditional probabilities are multi-staged experiments, which are best visualized using **Probability Trees**:

![Probability Trees](Assets/1.%20Review%20of%20Probability%20Theory.md/Probability%20Tree.png)

Instead of calculating conditional probabilities from scratch, some questions provide the conditional probability $P(A|B)$ (or the components to do so!) and ask us to **find the reverse** - $P(B|A)$.

$$
    P(B|A) = \frac{P(B \cap A)}{P(A)}
$$

The formula is the same as before, but the issue is that the unconditional probability of event A is usually not given. This problem is accounted for in **Bayes Theorem**:

$$
\begin{aligned}
    A &= (A \cap B) + (A \cap B^c) \\
    P(A) &= P(A \cap B) + P(A \cap B^c) \\
    P(A) &= P(A|B) \cdot P(B) + P(A|B^c) \cdot P(B^c) \\
    \\
    \therefore P(B|A) &= \frac{P(A|B) \cdot P(B)}{P(A|B) \cdot P(B) + P(A|B^c) \cdot P(B^c)}
\end{aligned}
$$

Note that if the Conditional Probability of A given B is the same as the unconditional probability of A, then **events A and B are independent**; B has no effect on A.

Thus, the **probability of an intersection** of two independent events is simply their product:

$$
\begin{aligned}
    P(A|B) &= \frac{P(A \cap B)}{P(B)} \\
    P(A) &= \frac{P(A \cap B)}{P(B)} \\
    P(A \cap B) &= P(A) \cdot P(B)
\end{aligned}
$$

## **Random Variables**

Unlike rolling a dice, the outcome of most experiments are **non-numeric**, which makes them hard to work with. For instance, the outcomes of a coin toss are "Heads" and "Tails".

A **Random Variable** is a **many to one function** that *maps* each outcome to a single real number. Each outcome must have only one corresponding number, but different outcomes can have the same value.

!!! Note

    Although the mapping is deterministic, the underlying experiment is still random which makes the overall process still random.

<!-- Obtained from Helping With Math -->
![Many to one function](Assets/1.%20Review%20of%20Probability%20Theory.md/Many%20to%20One%20Function.png)

<!-- Obtained from DSA201 Notes -->
![Random Variable](Assets/1.%20Review%20of%20Probability%20Theory.md/Random%20Variable.png)

Random variables are denoted using **upper case letters** (X, Y, Z) while their corresponding values are denoted using **lower case letters** (x, y, z) and their appropriate **subscripts**.

The notation $X(s) = x_1$ denotes that the random variable $X$ maps the outcome $s$ to the value of $x_1$. But if the outcome is omitted, then $X = x$ denotes ALL outcomes.

The **range of possible values** that the random variable can take is known as its **Support**. There are two main types of random variables - **Discrete** and **Continuous**, which represent **countable** and **uncountable** supports respectively.

### **Probability Distributions**

Similar to how a random variable maps the outcomes to a real number, a **Probability Distribution** is a function that maps the outcomes to its **probability of occurrence**.

### **Moments**

### **Tail Weight**

### **Other Metrics**

## **Empirical Distributions**