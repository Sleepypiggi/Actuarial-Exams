# **Frequency Models**

## **Counting Distributions**

Number of claims
P_k notation

PGF is provided for all discrete distributions in case

### **Poisson Distribution**

The **Poisson Distribution** is used to count the number of random events in a **specified unit of space or time**.

It only has **one parameter** $\lambda$, the **mean** number of occurrences in the specified unit of space or time. One key property is that its **mean and variance are both equal** to $\lambda$.

$$
\begin{aligned}
    N &\sim \text{Poisson}(\lambda) \\
    \\
    p_k &= \frac{e^{-\lambda} \cdot \lambda^k}{k!} \\
    \\
    E(N) &= \lambda \\
    Var (N) &= \lambda
\end{aligned}
$$

The sum of independent poisson random variables is **still poisson**:

$$
\begin{aligned}
    N_k &\sim \text{Poisson}(\lambda_k) \\
    N &= N_1 + N_2 + ... + N_k \\
    \therefore N &\sim \text{Poisson} (\lambda_1 + \lambda_2 + ... + \lambda_k)
\end{aligned}
$$

### **Bernoulli Distribution**

The **Bernoulli Distribution** is used to determine the outcome of a **Bernoulli Trial**. They are experiments with only **two possible outcomes**.

For a **Standard Bernoulli Distribution**, the two outcomes are **Successes and Failures**, denoted by 1 and 0 respectively:

$$
\begin{aligned}
    X &\sim \text{Bernoulli} (q) \\
    \\
    p_k &=
    \begin{cases}
        \text{Success } (1),& \text{Probability} = q, \\
        \text{Failure } (0),& \text{Probability} = 1-q
    \end{cases} \\
    \\
    E(X) &= q \\
    Var (X) &= q(1-q)
\end{aligned}
$$

However, the **Bernoulli Shortcut** generalizes this for **any two mutually exclusive outcomes**, denoted by $a$ and $b$ respectively:

$$
\begin{aligned}
    Y &= (a-b)X + b \\
    \\
    Y &=
    \begin{cases}
        \text{Outcome 1 } (a),& \text{Probability} = q, \\
        \text{Outcome 2 } (b),& \text{Probability} = 1-q
    \end{cases} \\
    \\
    E(Y)
    &= E[(a-b)X + b] \\
    &= (a-b)q + b \\
    \\
    Var (Y)
    &= Var[(a-b)X + b] \\
    &= (a-b)^2 \cdot q(1-q)
\end{aligned}
$$

Note that there is no need to memorize the mean and variance for the bernoulli shortcut - they can be easily derived from the standard distribution.

### **Binomial Distribution**

The **Binomial Distribution** is used to count the **number of successes** out of a **fixed number of independent Standard Bernoulli Trials**.

It has **two parameters**:

1. The **number** of independent trials, $m$
2. The **probability** of success for each trial, $q$

$$
\begin{aligned}
    N &\sim \text{Binomial} (m, q) \\
    \\
    p_k &= {m \choose k} q^k (1-q)^{1-k} \\
    \\
    E(N) &= nq \\
    Var (N) &= nq(1-q)
\end{aligned}
$$

The binomial distribution is actually the **sum of $m$ independent standard bernoulli variables** with the *same probability*:

$$
\begin{aligned}
    X_k &\sim \text{Bernoulli} (q) \\
    N &= X_1 + X_2 + ... + X_m \\
    \therefore N &\sim \text{Binomial} (m, q)
\end{aligned}
$$

!!! Note

    A bernoulli distribution is simply a binomial distribution with $m=1$.

Similarly, the sum of independent binomial variables with the *same probability* (which is simply the sum of *even more* independent standard bernoulli variables), is **still binomial**:

$$
\begin{aligned}
    N_k &\sim \text{Binomial}(m, q) \\
    N &= N_1 + N_2 + ... + N_k \\
    \therefore N &\sim \text{Binomial} (m_1 + m_2 + ... + m_k, q)
\end{aligned}
$$

### **Geometric Distribution**

The **Geometric Distribution** can be understood in one of two ways:

1. **Number of independent bernoulli trials** needed to get the first success, $N \in \set{1, 2, 3, ...}$
2. **Number of bernoulli failures** needed to get the first success, $F \in \set{0, 1, 2, ...}$

If not explicitly stated, the two intepretations can be distinguished from their supports - there must be at least 1 trial but there can be 0 failures. It is useful to **remember just one intepretation** and understand how they are related:

$$
    F = N-1
$$

Second case
k represent number of failures , 01234...

$$
\begin{aligned}
    p_k &= (1-q)^{k} \cdot q \\
    \\
    E(N) &= \frac{1-p}{p} \\
    Var (N) &= \frac{1-p}{p^2}
\end{aligned}
$$

### **Negative Binomial Distribution**

## (a, b, 0) Recursion

## (a, b, 1) Modification
